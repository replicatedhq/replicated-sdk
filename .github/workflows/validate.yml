name: PR/main branch CI

on:
  pull_request:
    branches:
      - main
  push:
    branches:
      - main

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

env:
  APP_SLUG: replicated-sdk-e2e

jobs:
  validate:
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v4
      - uses: dagger/dagger-for-github@8.0.0
        env:
          OP_SERVICE_ACCOUNT: ${{ secrets.OP_SERVICE_ACCOUNT }}
        with:
          verb: call
          args: validate --progress=plain --op-service-account=env:OP_SERVICE_ACCOUNT


  validate-e2e:
    runs-on: ubuntu-22.04
    needs: [ create-test-release, cmx-versions ]
    strategy:
      fail-fast: false
      matrix:
        cluster: ${{ fromJson(needs.cmx-versions.outputs.versions-to-test) }}
    env:
      LICENSE_ID: ${{ needs.create-test-release.outputs.license-id }}
      CHANNEL_SLUG: ${{ needs.create-test-release.outputs.channel-slug }}
      LICENSE_FIELDS: '[{"name":"expires_at","value": ""},{"name":"num_seats","value":"10"}]'
    steps:
      - uses: actions/checkout@v4

      - name: Create cluster
        id: create-cluster
        uses: replicatedhq/replicated-actions/create-cluster@v1.17.0
        with:
          api-token: ${{ secrets.C11Y_MATRIX_TOKEN }}
          kubernetes-distribution: ${{ matrix.cluster.distribution }}
          kubernetes-version: ${{ matrix.cluster.version }}
          cluster-name: automated-${{ github.run_id }}-${{ matrix.cluster.distribution }}-${{ matrix.cluster.version }}
          ttl: 2h
          export-kubeconfig: true

      - name: Install via Helm as standalone in integration mode
        run: helm install replicated oci://ttl.sh/automated-${{ github.run_id }}/replicated --version 0.0.0 --set integration.licenseID=$LICENSE_ID --set image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set image.tag=24h --wait --timeout 2m

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'true'

      - name: Uninstall replicated via Helm
        run: helm uninstall replicated --wait --timeout 2m

      - name: Install via kubectl as standalone in integration mode
        run: |
          helm template replicated oci://ttl.sh/automated-${{ github.run_id }}/replicated --version 0.0.0 --set integration.licenseID=$LICENSE_ID --set image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set image.tag=24h | kubectl apply -f -
          kubectl rollout status deployment replicated --timeout=2m

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'true'
          deployed-via-kubectl: 'true'

      - name: Uninstall replicated via kubectl
        run: |
          helm template replicated oci://ttl.sh/automated-${{ github.run_id }}/replicated --version 0.0.0 --set integration.licenseID=$LICENSE_ID --set image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set image.tag=24h | kubectl delete -f -
          kubectl wait --for=delete deployment/replicated --timeout=2m

      - name: Login to registry
        run: helm registry login registry.replicated.com --username $LICENSE_ID --password $LICENSE_ID

      - name: Install via Helm as subchart in integration mode
        run: helm install test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h --wait --timeout 2m

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'true'

      - name: Uninstall test-chart via Helm
        run: helm uninstall test-chart --wait --timeout 2m

      - name: Install via kubectl as subchart in integration mode
        run: |
          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h | kubectl apply -f -
          kubectl rollout status deployment test-chart --timeout=2m
          kubectl rollout status deployment replicated --timeout=2m

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'true'
          deployed-via-kubectl: 'true'

      - name: Uninstall test-chart via kubectl
        run: |
          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h | kubectl delete -f -
          kubectl wait --for=delete deployment/test-chart --timeout=2m
          kubectl wait --for=delete deployment/replicated --timeout=2m

      # we have to explicitly disable integration mode here because we're using a "dev" license
      - name: Install via Helm as subchart in production mode
        run: helm install test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h --wait --timeout 2m

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'false'

      - name: Upgrade via Helm as subchart in production mode to a new version
        run: |
          oldpodname=$(kubectl get pods -l app.kubernetes.io/name=replicated -o jsonpath='{.items[0].metadata.name}')

          helm upgrade test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.versionLabel=1.0.0 --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h --wait --timeout 2m

          COUNTER=1
          while kubectl get pods -l app.kubernetes.io/name=replicated -o jsonpath='{.items[0].metadata.name}' | grep -q $oldpodname; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Pod did not restart after upgrade"
              exit 1
            fi
            sleep 1
          done

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          version-label: '1.0.0'
          integration-enabled: 'false'

      - name: Uninstall test-chart via Helm
        run: helm uninstall test-chart --wait --timeout 2m

      # we have to explicitly disable integration mode here because we're using a "dev" license
      - name: Install via kubectl as subchart in production mode
        run: |
          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h | kubectl apply -f -
          kubectl rollout status deployment test-chart --timeout=2m
          kubectl rollout status deployment replicated --timeout=2m

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'false'
          deployed-via-kubectl: 'true'

      - name: Upgrade via kubectl as subchart in production mode
        run: |
          oldpodname=$(kubectl get pods -l app.kubernetes.io/name=replicated -o jsonpath='{.items[0].metadata.name}')

          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.versionLabel=1.0.0 --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h | kubectl apply -f -
          kubectl rollout status deployment test-chart --timeout=2m
          kubectl rollout status deployment replicated --timeout=2m

          COUNTER=1
          while kubectl get pods -l app.kubernetes.io/name=replicated -o jsonpath='{.items[0].metadata.name}' | grep -q $oldpodname; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Pod did not restart after upgrade"
              exit 1
            fi
            sleep 1
          done

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'false'
          version-label: '1.0.0'
          deployed-via-kubectl: 'true'

      - name: Uninstall test-chart via kubectl
        run: |
          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h | kubectl delete -f -
          kubectl wait --for=delete deployment/test-chart --timeout=2m
          kubectl wait --for=delete deployment/replicated --timeout=2m

      # validate status informers
      - name: Create empty status informers for validation
        run: |
          cat << EOF > test-values.yaml
          replicated:
            statusInformers: []
          EOF

      - name: Install via Helm as subchart in production mode and pass empty status informers
        run: |
          helm install test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h -f test-values.yaml --wait --timeout 2m

          COUNTER=1
          while ! kubectl logs deploy/replicated | grep -qv 'Generating status informers from Helm release'; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Did not receive empty status informers"
              kubectl logs deploy/replicated
              exit 1
            fi
            sleep 1
          done

      - name: Upgrade via Helm as subchart in production mode to use default status informers
        run: |
          helm upgrade test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h --wait --timeout 2m

          COUNTER=1
          while ! kubectl logs deploy/replicated | grep -q 'Generating status informers from Helm release'; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Did not receive default status informers"
              kubectl logs deploy/replicated
              exit 1
            fi
            sleep 1
          done

      - name: Uninstall test-chart via Helm
        run: helm uninstall test-chart --wait --timeout 2m

      - name: Install via kubectl as subchart in production mode and pass empty status informers
        run: |
          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h -f test-values.yaml | kubectl apply -f -
          kubectl rollout status deployment test-chart --timeout=2m
          kubectl rollout status deployment replicated --timeout=2m

          COUNTER=1
          while ! kubectl logs deploy/replicated | grep -qv 'Generating status informers from Helm release'; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Did not receive empty status informers"
              kubectl logs deploy/replicated
              exit 1
            fi
            sleep 1
          done

      - name: Uninstall test-chart via kubectl
        run: |
          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h -f test-values.yaml | kubectl delete -f -
          kubectl wait --for=delete deployment/test-chart --timeout=2m
          kubectl wait --for=delete deployment/replicated --timeout=2m

      # validate airgap
      - name: Download support-bundle binary
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz

      - name: Install via Helm as subchart in production airgap mode
        run: |
          helm install test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.isAirgap=true --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h --wait --timeout 2m

          COUNTER=1
          while ! kubectl get secret/replicated-instance-report; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Did not create replicated-instance-report secret"
              exit 1
            fi
            sleep 1
          done

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'false'
          is-airgap: 'true'

      - name: Validate support bundle contents
        run: |
          ./support-bundle --load-cluster-specs --interactive=false
          tar xzf support-bundle-*.tar.gz
          if ! ls support-bundle-*/secrets/*/replicated-instance-report/report.json; then
            echo "Did not find replicated-instance-report in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/secrets/*/replicated-custom-app-metrics-report/report.json; then
            echo "Did not find replicated-custom-app-metrics-report in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated/logs/*/*.log; then
            echo "Did not find replicated pod logs in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated-sdk/*/*/replicated-app-history-stdout.txt; then
            echo "Did not find replicated-app-history-stdout.txt in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated-sdk/*/*/replicated-app-updates-stdout.txt; then
            echo "Did not find replicated-app-updates-stdout.txt in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated-sdk/*/*/replicated-app-info-stdout.txt; then
            echo "Did not find replicated-app-info-stdout.txt in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated-sdk/*/*/replicated-license-info-stdout.txt; then
            echo "Did not find replicated-license-info-stdout.txt in support bundle"
            exit 1
          fi
          rm -rf support-bundle-*

      - name: Uninstall test-chart via Helm
        run: |
          helm uninstall test-chart --wait --timeout 2m

          COUNTER=1
          while kubectl get secret/replicated-instance-report; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Did not delete replicated-instance-report secret"
              exit 1
            fi
            sleep 1
          done

      - name: Install via kubectl as subchart in production airgap mode
        run: |
          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.isAirgap=true --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h | kubectl apply -f -
          kubectl rollout status deployment test-chart --timeout=2m
          kubectl rollout status deployment replicated --timeout=2m

          COUNTER=1
          while ! kubectl get secret/replicated-instance-report; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Did not create replicated-instance-report secret"
              exit 1
            fi
            sleep 1
          done

      - name: Validate endpoints
        uses: ./.github/actions/validate-endpoints
        with:
          license-id: ${{ env.LICENSE_ID }}
          license-fields: ${{ env.LICENSE_FIELDS }}
          integration-enabled: 'false'
          deployed-via-kubectl: 'true'
          is-airgap: 'true'

      - name: Validate support bundle contents
        run: |
          ./support-bundle --load-cluster-specs --interactive=false
          tar xzf support-bundle-*.tar.gz
          if ! ls support-bundle-*/secrets/*/replicated-instance-report/report.json; then
            echo "Did not find replicated-instance-report in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/secrets/*/replicated-custom-app-metrics-report/report.json; then
            echo "Did not find replicated-custom-app-metrics-report in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated/logs/*/*.log; then
            echo "Did not find replicated pod logs in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated-sdk/*/*/replicated-app-history-stdout.txt; then
            echo "Did not find replicated-app-history-stdout.txt in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated-sdk/*/*/replicated-app-updates-stdout.txt; then
            echo "Did not find replicated-app-updates-stdout.txt in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated-sdk/*/*/replicated-app-info-stdout.txt; then
            echo "Did not find replicated-app-info-stdout.txt in support bundle"
            exit 1
          fi
          if ! ls support-bundle-*/replicated-sdk/*/*/replicated-license-info-stdout.txt; then
            echo "Did not find replicated-license-info-stdout.txt in support bundle"
            exit 1
          fi
          rm -rf support-bundle-*

      - name: Uninstall test-chart via kubectl
        run: |
          helm template test-chart oci://registry.replicated.com/$APP_SLUG/$CHANNEL_SLUG/test-chart --set replicated.integration.enabled=false --set replicated.isAirgap=true --set replicated.image.repository=ttl.sh/automated-${{ github.run_id }}/replicated/replicated-sdk --set replicated.image.tag=24h | kubectl delete -f -
          kubectl wait --for=delete deployment/test-chart --timeout=2m
          kubectl wait --for=delete deployment/replicated --timeout=2m

          COUNTER=1
          while kubectl get secret/replicated-instance-report; do
            ((COUNTER += 1))
            if [ $COUNTER -gt 60 ]; then
              echo "Did not delete replicated-instance-report secret"
              exit 1
            fi
            sleep 1
          done

      - name: Generate support bundle on failure
        if: failure()
        uses: ./.github/actions/generate-support-bundle
        with:
          namespace: default
          artifact-name: ${{ github.job }}-${{ matrix.cluster.distribution }}-${{ matrix.cluster.version }}-support-bundle

      - name: Remove Cluster
        uses: replicatedhq/replicated-actions/remove-cluster@v1.17.0
        if: ${{ always() && steps.create-cluster.outputs.cluster-id != '' }}
        with:
          api-token: ${{ secrets.C11Y_MATRIX_TOKEN }}
          cluster-id: ${{ steps.create-cluster.outputs.cluster-id }}

  cleanup-test-release:
    runs-on: ubuntu-22.04
    needs: [ create-test-release, validate-e2e ]
    steps:
      - name: Archive Customer
        if: ${{ needs.create-test-release.outputs.customer-id != '' }}
        uses: replicatedhq/replicated-actions/archive-customer@v1.17.0
        with:
          api-token: ${{ secrets.C11Y_MATRIX_TOKEN }}
          customer-id: ${{ needs.create-test-release.outputs.customer-id }}

      - name: Archive Channel
        if: ${{ needs.create-test-release.outputs.channel-slug != '' }}
        uses: replicatedhq/replicated-actions/archive-channel@v1.17.0
        with:
          app-slug: ${{ env.APP_SLUG }}
          api-token: ${{ secrets.C11Y_MATRIX_TOKEN }}
          channel-slug: ${{ needs.create-test-release.outputs.channel-slug }}
